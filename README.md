# PRISMA-trAIce: A Reporting Guideline for AI-Assisted Evidence Synthesis
PRISMA-trAIce (Transparent Reporting of Artificial Intelligence in Comprehensive Evidence-synthesis) is a proposed extension to the PRISMA 2020 Statement. It aims to establish uniform and transparent standards for reporting the use of Artificial Intelligence (AI) as a methodological tool in Systematic Literature Reviews (SLRs).

## üöÄ The Problem
Systematic Reviews are the gold standard for evidence synthesis, but they are extremely demanding in terms of time and personnel. AI tools, especially Large Language Models (LLMs), can significantly accelerate this process. However, a standard for transparently reporting the use of these tools to ensure scientific traceability and trustworthiness is currently missing. Existing guidelines like PRISMA-AI focus on AI as a subject of research, not as a tool. PRISMA-trAIce closes this critical gap.

## üå± A Living Guideline
This project is designed as a "Living Guideline". In a field as dynamic as AI, a static standard quickly becomes obsolete. We therefore actively invite the scientific community to help shape and evolve this guideline.

Stable Anchor: This GitHub repository serves as the "Single Source of Truth". Here you will find the most current version of the checklist and all associated materials.

Community Hub: For discussions, questions, and rapid collaboration, we have set up a Discord server. Join our community on Discord!

## ‚úçÔ∏è How to Cite
If you use or refer to PRISMA-trAIce in your research, please cite both the original publication and this GitHub repository to specify the version used.

Original Paper:

Holst, D., Koch, J., Moenck, K., Gomse, M., & Sch√ºppstuhl, T. (YEAR). PRISMA-trAIce: A Proposed Checklist for Transparent Reporting of Artificial Intelligence in Comprehensive Evidence-synthesis. [Journal Name], [Volume], [Pages]. [DOI-Link]
(Please update upon publication)

GitHub Repository (for a specific version):

Holst, D., Koch, J., et al. (YEAR). PRISMA-trAIce: A Living Reporting Guideline (Version X.X.X). GitHub. Retrieved from [https://github.com/cqh4046/PRISMA-trAIce](https://github.com/cqh4046/PRISMA-trAIce)

## ‚úÖ The PRISMA-trAIce Checklist
The following checklist provides the recommended items for reporting the use of AI tools in systematic reviews. For detailed explanations and examples, please refer to the full publication.

Section | Item ID | Recommended Reporting Item
| -------- | :---: | ------- |
TITLE | P-trAIce T1 | Indicate the use of AI in the title or subtitle if it played a substantial role (e.g., in screening or data extraction).
ABSTRACT | P-trAIce A1 | Briefly summarize the AI tool(s) used, the review stage(s) where they were applied, and their primary role.
INTRO | P-trAIce I1 | Briefly state the rationale for using AI tools for specific tasks (e.g., to manage a large volume of literature).
METHODS | P-trAIce M1 | Protocol: State if the use of AI was pre-specified in a protocol and report any deviations.
|| P-trAIce M2 | Tool Identification: Specify the name, version, and provider for each AI tool. Provide access details (e.g., URL, repository).
|| P-trAIce M3 | Tool Purpose: Describe the specific SLR stage and the precise task the AI was intended to perform.
|| P-trAIce M4 | Input Data: Describe the data provided to the AI tool (e.g., search results, abstracts, full texts, training data).
|| P-trAIce M5 | Output Data: Describe the output generated by the AI tool, including its format and any post-processing.
|| P-trAIce M6 | Prompts: For LLMs, report the prompts, key parameters (e.g., temperature), and any refinement process.
|| P-trAIce M7 | Settings: For other AI tools, describe key settings, parameters, or configurations that could influence performance.
|| P-trAIce M8 | Human Oversight: Describe the human interaction process (e.g., number of reviewers, verification process, discrepancy resolution).
|| P-trAIce M9 | Performance: Describe methods used to evaluate AI performance (e.g., reference standard, metrics), if applicable.
|| P-trAIce M10| Ethics: Describe data management, storage, and measures taken to ensure privacy, security, and compliance.
RESULTS | P-trAIce R1| Flow Diagram: In the PRISMA flow diagram, distinguish between records handled by AI versus human reviewers.
|| P-trAIce R2 | Performance Metrics: Report the results of any AI performance evaluations conducted.
DISCUSSION | P-trAIce D1 | Limitations: Discuss any limitations in the use of AI (e.g., technical issues, biases) and their potential impact.
|| P-trAIce D2 | Implications: Briefly discuss the experience of using AI tools (e.g., benefits, challenges) for future reviews.

## üìä The PRISMA-trAIce Flow Diagram
To transparently report the study selection process, we propose an adaptation of the PRISMA 2020 Flow Diagram. The template explicitly distinguishes between administrative, rule-based tools (e.g., for deduplication) and AI systems that perform evaluative tasks.

![PRISMA-trAIce Flow Diagram](https://github.com/cqh4046/PRISMA-trAIce/blob/main/PRISMA-trAIce_flow_diagram.png)

## ü§ù How to Contribute
We welcome community contributions! There are several ways to get involved:

Start a Discussion: Have an idea, suggestion, or question? Open a new Issue to start a discussion.

Propose Changes: If you want to propose a specific change to the checklist, please open a Pull Request. Clearly describe the reason for your change.

Give Feedback: Participate in the discussions in existing Issues and Pull Requests.

Join the Community: Join our [Discord Server](https://discord.gg/DrDFBpEb53) to chat with other community members.

## üìÑ License
This project is licensed under the MIT License. This means you are free to use, modify, and distribute the content as long as you retain the original copyright notice. See the LICENSE file for more details.
